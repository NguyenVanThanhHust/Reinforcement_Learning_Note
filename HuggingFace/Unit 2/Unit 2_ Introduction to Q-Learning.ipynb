{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMi5p4+c9jWgEBszXRU7V4U"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"523a7a8673544bfc9e2a592f1f99661c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ea86451f170a4c75a664a4f19dfc0d82","IPY_MODEL_1fb18bbca03845b6a3e42694030e5c29","IPY_MODEL_05adb76666ac4de18f20d9c67410d1a8"],"layout":"IPY_MODEL_806afb9d77ff4634a25a5a5dcececccb"}},"ea86451f170a4c75a664a4f19dfc0d82":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_93e99ee0d9374b648912adfcca3c1fdb","placeholder":"​","style":"IPY_MODEL_fdc4886eb00349d1b6f3919894d17e29","value":"100%"}},"1fb18bbca03845b6a3e42694030e5c29":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a55635d715db4e95988488d96afaec2a","max":100,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5fda0a52647e42cd819b0c37aafc098d","value":100}},"05adb76666ac4de18f20d9c67410d1a8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ac4a2c4960154efcb1ea5ccf127489af","placeholder":"​","style":"IPY_MODEL_425705caff09494dbb3e1989e209d92d","value":" 100/100 [00:00&lt;00:00, 2389.85it/s]"}},"806afb9d77ff4634a25a5a5dcececccb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93e99ee0d9374b648912adfcca3c1fdb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fdc4886eb00349d1b6f3919894d17e29":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a55635d715db4e95988488d96afaec2a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5fda0a52647e42cd819b0c37aafc098d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ac4a2c4960154efcb1ea5ccf127489af":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"425705caff09494dbb3e1989e209d92d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"prShTBYkWzkI","executionInfo":{"status":"ok","timestamp":1671705004547,"user_tz":-420,"elapsed":26190,"user":{"displayName":"Thanh Nguyen","userId":"01424044865424544936"}}},"outputs":[],"source":["\n","%%capture\n","!pip install pyglet==1.5.1 \n","!apt install python-opengl\n","!apt install ffmpeg\n","!apt install xvfb\n","!pip3 install pyvirtualdisplay\n","\n","# Virtual display\n","from pyvirtualdisplay import Display\n","\n","virtual_display = Display(visible=0, size=(1400, 900))\n","virtual_display.start()\n","     "]},{"cell_type":"code","source":["\n","%%capture\n","!pip install gym==0.24 # We install the newest gym version for the Taxi-v3 \"rgb_array version\"\n","!pip install pygame\n","!pip install numpy\n","\n","!pip install huggingface_hub\n","!pip install pickle5\n","!pip install pyyaml==6.0 # avoid key error metadata\n","!pip install imageio imageio_ffmpeg"],"metadata":{"id":"mKOoDVwTYOAR","executionInfo":{"status":"ok","timestamp":1671705049439,"user_tz":-420,"elapsed":44921,"user":{"displayName":"Thanh Nguyen","userId":"01424044865424544936"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import gym\n","import random\n","import imageio\n","import os\n","\n","import pickle5 as pickle\n","from tqdm.notebook import tqdm"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"isuJh7SAYRBF","executionInfo":{"status":"ok","timestamp":1671705049991,"user_tz":-420,"elapsed":559,"user":{"displayName":"Thanh Nguyen","userId":"01424044865424544936"}},"outputId":"e5b431ca-14e1-4d36-d2cb-eaec3f4e4c2b"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["Warning: Gym version v0.24.0 has a number of critical issues with `gym.make` such that the `reset` and `step` functions are called before returning the environment. It is recommend to downgrading to v0.23.1 or upgrading to v0.25.1\n"]}]},{"cell_type":"code","source":["# Create the FrozenLake-v1 environment using 4x4 map and non-slippery version\n","env = gym.make(\"FrozenLake-v1\", map_name=\"4x4\", is_slippery=False)"],"metadata":{"id":"CPKdRUEdYYEQ","executionInfo":{"status":"ok","timestamp":1671705184577,"user_tz":-420,"elapsed":5,"user":{"displayName":"Thanh Nguyen","userId":"01424044865424544936"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Check observation\n","env.reset()\n","print(\"Observation\")\n","print(\"Observation space: \", env.observation_space)\n","print(\"Sample observation: \", env.observation_space.sample())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7CDuXPDUYoL3","executionInfo":{"status":"ok","timestamp":1671705342703,"user_tz":-420,"elapsed":9,"user":{"displayName":"Thanh Nguyen","userId":"01424044865424544936"}},"outputId":"caa90fb7-f609-4fae-f1e7-5a7b8e2ee9b7"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Observation\n","Observation space:  Discrete(16)\n","Sample observation:  11\n"]}]},{"cell_type":"code","source":["# Check action space\n","print(\"Action: \")\n","print(\"Action space: \", env.action_space.n)\n","print(\"Action sample: \", env.action_space.sample())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6BQphCJ9ZyyI","executionInfo":{"status":"ok","timestamp":1671705403344,"user_tz":-420,"elapsed":12,"user":{"displayName":"Thanh Nguyen","userId":"01424044865424544936"}},"outputId":"d088d731-18a6-4bbd-8315-b4ed2f7c64a0"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Action: \n","Action space:  4\n","Action sample:  2\n"]}]},{"cell_type":"code","source":["state_space = env.observation_space.n\n","print(\"There are \", state_space, \" possible states\")\n","\n","action_space = env.action_space.n\n","print(\"There are \", action_space, \" possible actions\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qD6L-YNDaBXc","executionInfo":{"status":"ok","timestamp":1671705892382,"user_tz":-420,"elapsed":4,"user":{"displayName":"Thanh Nguyen","userId":"01424044865424544936"}},"outputId":"c5bda04e-8bdd-4371-d8b0-83a8058087ee"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["16 4\n"]}]},{"cell_type":"code","source":["def initialize_q_table(state_space, action_space):\n","  Qtable = np.zeros((state_space, action_space))\n","  return Qtable"],"metadata":{"id":"OEhg1Gi0bPc6","executionInfo":{"status":"ok","timestamp":1671705931964,"user_tz":-420,"elapsed":509,"user":{"displayName":"Thanh Nguyen","userId":"01424044865424544936"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["Qtable_frozenlake = initialize_q_table(state_space, action_space)"],"metadata":{"id":"1-PmZHmYcCom","executionInfo":{"status":"ok","timestamp":1671706284690,"user_tz":-420,"elapsed":3,"user":{"displayName":"Thanh Nguyen","userId":"01424044865424544936"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["import random\n","\n","def epsilon_greed_policy(Qtable, state, epsilon):\n","  # Randomly generate a number between 0 and 1\n","  random_num = random.uniform(0, 1)\n","  # If random_num > epsiloon, act with highest value given state\n","  if random_num > epsilon:\n","    action = np.argmax(Qtable[state])\n","  else:\n","    action = env.action_space.sample()\n","  return action"],"metadata":{"id":"tEn7mVBrdYZI","executionInfo":{"status":"ok","timestamp":1671706568907,"user_tz":-420,"elapsed":7,"user":{"displayName":"Thanh Nguyen","userId":"01424044865424544936"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["def greedy_policy(Qtable, state):\n","  # Exploitation: take the action with highest value\n","  action  = np.argmax(Qtable[state])\n","  return action"],"metadata":{"id":"5qY6A4TGeeIU","executionInfo":{"status":"ok","timestamp":1671707028323,"user_tz":-420,"elapsed":706,"user":{"displayName":"Thanh Nguyen","userId":"01424044865424544936"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["\n","# Training parameters\n","n_training_episodes = 10000  # Total training episodes\n","learning_rate = 0.7          # Learning rate\n","\n","# Evaluation parameters\n","n_eval_episodes = 100        # Total number of test episodes\n","\n","# Environment parameters\n","env_id = \"FrozenLake-v1\"     # Name of the environment\n","max_steps = 99               # Max steps per episode\n","gamma = 0.95                 # Discounting rate\n","eval_seed = []               # The evaluation seed of the environment\n","\n","# Exploration parameters\n","max_epsilon = 1.0             # Exploration probability at start\n","min_epsilon = 0.05            # Minimum exploration probability \n","decay_rate = 0.0005            # Exponential decay rate for exploration prob"],"metadata":{"id":"gBu8t6iIgODB","executionInfo":{"status":"ok","timestamp":1671707042949,"user_tz":-420,"elapsed":6,"user":{"displayName":"Thanh Nguyen","userId":"01424044865424544936"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["def train(n_training_episodes, min_epsilon, max_epsilon, decay_rate, env, max_steps, Qtable):\n","  for episode in range(n_training_episodes):\n","    epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_rate*episode)\n","    state = env.reset()\n","    step = 0\n","    done = False\n","\n","    # repeat\n","    for step in range(max_steps):\n","      # Choose the action A at time t using the epsilon greed policy\n","      action = epsilon_greed_policy(Qtable, state, epsilon)\n","\n","      # Take action and get new state, reward\n","      new_state, reward, done, info = env.step(action)\n","\n","      # Update Q table\n","      Qtable[state][action] = Qtable[state][action] + learning_rate * (reward + gamma * np.max(Qtable[new_state]) - Qtable[state][action])   \n","\n","      if done:\n","        break\n","\n","      # Move to new state      \n","      state = new_state\n","  return Qtable"],"metadata":{"id":"X5jMi8FugSCx","executionInfo":{"status":"ok","timestamp":1671707860099,"user_tz":-420,"elapsed":5,"user":{"displayName":"Thanh Nguyen","userId":"01424044865424544936"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["Qtable_frozenlake = train(n_training_episodes, min_epsilon, max_epsilon, decay_rate, env, max_steps, Qtable_frozenlake)\n"],"metadata":{"id":"g1lg-UHoiiOK","executionInfo":{"status":"ok","timestamp":1671708115352,"user_tz":-420,"elapsed":3318,"user":{"displayName":"Thanh Nguyen","userId":"01424044865424544936"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["# Get the Q table\n","print(Qtable_frozenlake)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rzp63vM5jZov","executionInfo":{"status":"ok","timestamp":1671708115353,"user_tz":-420,"elapsed":11,"user":{"displayName":"Thanh Nguyen","userId":"01424044865424544936"}},"outputId":"7469bb6b-47a0-4ae7-8d02-72917db637f0"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.73509189 0.77378094 0.77378094 0.73509189]\n"," [0.73509189 0.         0.81450625 0.77378094]\n"," [0.77378094 0.857375   0.77378094 0.81450625]\n"," [0.81450625 0.         0.77378094 0.77378094]\n"," [0.77378094 0.81450625 0.         0.73509189]\n"," [0.         0.         0.         0.        ]\n"," [0.         0.9025     0.         0.81450625]\n"," [0.         0.         0.         0.        ]\n"," [0.81450625 0.         0.857375   0.77378094]\n"," [0.81450625 0.9025     0.9025     0.        ]\n"," [0.857375   0.95       0.         0.857375  ]\n"," [0.         0.         0.         0.        ]\n"," [0.         0.         0.         0.        ]\n"," [0.         0.9025     0.95       0.857375  ]\n"," [0.9025     0.95       1.         0.9025    ]\n"," [0.         0.         0.         0.        ]]\n"]}]},{"cell_type":"code","source":["# Define evaluation\n","\n","def evaluate_agent(env, max_steps, n_eval_episodes, Q, seed):\n","  \"\"\"\n","  Evaluate the agent for ``n_eval_episodes`` episodes and returns average reward and std of reward.\n","  :param env: The evaluation environment\n","  :param n_eval_episodes: Number of episode to evaluate the agent\n","  :param Q: The Q-table\n","  :param seed: The evaluation seed array (for taxi-v3)\n","  \"\"\"\n","  episode_rewards = []\n","  for episode in tqdm(range(n_eval_episodes)):\n","    if seed:\n","      state = env.reset(seed=seed[episode])\n","    else:\n","      state = env.reset()\n","    step = 0\n","    done = False\n","    total_rewards_ep = 0\n","    \n","    for step in range(max_steps):\n","      # Take the action (index) that have the maximum expected future reward given that state\n","      action = np.argmax(Q[state][:])\n","      new_state, reward, done, info = env.step(action)\n","      total_rewards_ep += reward\n","        \n","      if done:\n","        break\n","      state = new_state\n","    episode_rewards.append(total_rewards_ep)\n","  mean_reward = np.mean(episode_rewards)\n","  std_reward = np.std(episode_rewards)\n","\n","  return mean_reward, std_reward"],"metadata":{"id":"mWy2QLGijguB","executionInfo":{"status":"ok","timestamp":1671708149139,"user_tz":-420,"elapsed":500,"user":{"displayName":"Thanh Nguyen","userId":"01424044865424544936"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["# Evaluate our Agent\n","mean_reward, std_reward = evaluate_agent(env, max_steps, n_eval_episodes, Qtable_frozenlake, eval_seed)\n","print(f\"Mean_reward={mean_reward:.2f} +/- {std_reward:.2f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["523a7a8673544bfc9e2a592f1f99661c","ea86451f170a4c75a664a4f19dfc0d82","1fb18bbca03845b6a3e42694030e5c29","05adb76666ac4de18f20d9c67410d1a8","806afb9d77ff4634a25a5a5dcececccb","93e99ee0d9374b648912adfcca3c1fdb","fdc4886eb00349d1b6f3919894d17e29","a55635d715db4e95988488d96afaec2a","5fda0a52647e42cd819b0c37aafc098d","ac4a2c4960154efcb1ea5ccf127489af","425705caff09494dbb3e1989e209d92d"]},"id":"ipxk87hKkgFM","executionInfo":{"status":"ok","timestamp":1671708156473,"user_tz":-420,"elapsed":693,"user":{"displayName":"Thanh Nguyen","userId":"01424044865424544936"}},"outputId":"5ed99264-3b9e-4d13-d64f-c0798a7aaac0"},"execution_count":30,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/100 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"523a7a8673544bfc9e2a592f1f99661c"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mean_reward=1.00 +/- 0.00\n"]}]},{"cell_type":"code","source":["\n","%%capture\n","from huggingface_hub import HfApi, HfFolder, Repository\n","from huggingface_hub.repocard import metadata_eval_result, metadata_save\n","\n","from pathlib import Path\n","import datetime\n","import json"],"metadata":{"id":"dgKRokXKkhq5","executionInfo":{"status":"ok","timestamp":1671708191908,"user_tz":-420,"elapsed":4,"user":{"displayName":"Thanh Nguyen","userId":"01424044865424544936"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["def record_video(env, Qtable, out_directory, fps=1):\n","  images = []  \n","  done = False\n","  state = env.reset(seed=random.randint(0,500))\n","  img = env.render(mode='rgb_array')\n","  images.append(img)\n","  while not done:\n","    # Take the action (index) that have the maximum expected future reward given that state\n","    action = np.argmax(Qtable[state][:])\n","    state, reward, done, info = env.step(action) # We directly put next_state = state for recording logic\n","    img = env.render(mode='rgb_array')\n","    images.append(img)\n","  imageio.mimsave(out_directory, [np.array(img) for i, img in enumerate(images)], fps=fps)"],"metadata":{"id":"fDScyEjFkqkR","executionInfo":{"status":"ok","timestamp":1671708211418,"user_tz":-420,"elapsed":518,"user":{"displayName":"Thanh Nguyen","userId":"01424044865424544936"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ycTvwYxTkvLM"},"execution_count":null,"outputs":[]}]}